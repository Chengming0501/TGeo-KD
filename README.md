# TGeo-KD
Exploiting Trilateral Geometry Towards Enhanced Knowledge Distillation
# Abstract
Knowledge distillation aims to train a compact student network using soft supervision from a larger teacher network and hard supervision from ground truths. However, determining an optimal knowledge fusion ratio that balances these supervisory signals remains challenging. Prior methods generally resort to a constant or heuristic-based variable ratio, which often falls short of an optimal balance. In this study, we introduce a novel adaptive method for learning a knowledge fusion ratio, inspired by the sample-wise trilateral geometry among the student prediction ($\mathcal{S}$), teacher prediction ($\mathcal{T}$), and ground truth ($\mathcal{G}$). Specifically, we first capture intra-sample geometric relations by capturing the edge and angle information within each ($\mathcal{S}$, $\mathcal{T}$, $\mathcal{G}$) triplet in Euclidean space. To counterbalance the impact of outliers, we extend to an inter-sample geometric relation, incorporating the teacher's average prediction ($\bar{\mathcal{T}})$ for samples within the same class. A simple neural network then learns the implicit mapping from the intra- and inter-sample relations to an adaptive, sample-wise knowledge fusion ratio. Our approach provides a simple, practical, and adaptable solution for knowledge distillation that can be used across various architectures and model sizes. Extensive experiments demonstrate consistent improvements and robustness over other loss re-weighting methods on image classification, attack detection, and click-through rate prediction.
